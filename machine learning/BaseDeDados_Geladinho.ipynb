{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cDm_ifyzgov4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_geladinhos = pd.read_csv('geladinhos.csv')"
      ],
      "metadata": {
        "id": "9iv8fXMmqLVX"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Converter as colunas para o tipo datetime\n",
        "base_geladinhos['data_cadastro'] = pd.to_datetime(base_geladinhos['data_cadastro'])\n",
        "base_geladinhos['data_hora_pedido'] = pd.to_datetime(base_geladinhos['data_hora_pedido'])\n",
        "\n",
        "# 2. Extrair componentes temporais\n",
        "base_geladinhos['ano_cadastro'] = base_geladinhos['data_cadastro'].dt.year\n",
        "base_geladinhos['mes_cadastro'] = base_geladinhos['data_cadastro'].dt.month\n",
        "base_geladinhos['dia_cadastro'] = base_geladinhos['data_cadastro'].dt.day\n",
        "base_geladinhos['dia_semana_cadastro'] = base_geladinhos['data_cadastro'].dt.dayofweek\n",
        "base_geladinhos['dia_do_ano_cadastro'] = base_geladinhos['data_cadastro'].dt.dayofyear\n",
        "base_geladinhos['semana_do_ano_cadastro'] = base_geladinhos['data_cadastro'].dt.isocalendar().week.astype(int)\n",
        "\n",
        "base_geladinhos['ano_pedido'] = base_geladinhos['data_hora_pedido'].dt.year\n",
        "base_geladinhos['mes_pedido'] = base_geladinhos['data_hora_pedido'].dt.month\n",
        "base_geladinhos['dia_pedido'] = base_geladinhos['data_hora_pedido'].dt.day\n",
        "base_geladinhos['hora_pedido'] = base_geladinhos['data_hora_pedido'].dt.hour\n",
        "base_geladinhos['minuto_pedido'] = base_geladinhos['data_hora_pedido'].dt.minute\n",
        "base_geladinhos['dia_semana_pedido'] = base_geladinhos['data_hora_pedido'].dt.dayofweek\n",
        "base_geladinhos['dia_do_ano_pedido'] = base_geladinhos['data_hora_pedido'].dt.dayofyear\n",
        "base_geladinhos['semana_do_ano_pedido'] = base_geladinhos['data_hora_pedido'].dt.isocalendar().week.astype(int)\n",
        "\n",
        "# 3. Criar features de tempo relativas (se desejar)\n",
        "base_geladinhos['dias_desde_cadastro_ate_pedido'] = (base_geladinhos['data_hora_pedido'] - base_geladinhos['data_cadastro']).dt.days\n",
        "\n",
        "def periodo_do_dia(hora):\n",
        "    if 5 <= hora < 12:\n",
        "        return 'manha'\n",
        "    elif 12 <= hora < 18:\n",
        "        return 'tarde'\n",
        "    else:\n",
        "        return 'noite'\n",
        "base_geladinhos['periodo_dia_pedido'] = base_geladinhos['hora_pedido'].apply(periodo_do_dia)\n",
        "\n",
        "# --- PASSO CRUCIAL: Remover as colunas originais de data/hora AGORA ---\n",
        "base_geladinhos = base_geladinhos.drop(columns=['data_cadastro', 'data_hora_pedido'])\n",
        "\n",
        "print(\"Tipos de dados após tratamento e remoção das colunas originais de data:\")\n",
        "print(base_geladinhos.dtypes)\n",
        "print(\"\\nColunas restantes:\")\n",
        "print(base_geladinhos.columns.tolist())"
      ],
      "metadata": {
        "id": "_fA8fxMrkFCs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1649880e-f410-4778-9912-962b1f03b16e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tipos de dados após tratamento e remoção das colunas originais de data:\n",
            "id_pedido                           int64\n",
            "id_cliente                          int64\n",
            "idade                               int64\n",
            "genero                             object\n",
            "cidade                             object\n",
            "bairro                             object\n",
            "é_estudante                          bool\n",
            "frequencia_visita                  object\n",
            "canal_compra                       object\n",
            "forma_pagamento                    object\n",
            "quantidade_itens                    int64\n",
            "sabor                              object\n",
            "categoria                          object\n",
            "preco_unitario                    float64\n",
            "valor_total_pedido                float64\n",
            "clima                              object\n",
            "ano_cadastro                        int32\n",
            "mes_cadastro                        int32\n",
            "dia_cadastro                        int32\n",
            "dia_semana_cadastro                 int32\n",
            "dia_do_ano_cadastro                 int32\n",
            "semana_do_ano_cadastro              int64\n",
            "ano_pedido                          int32\n",
            "mes_pedido                          int32\n",
            "dia_pedido                          int32\n",
            "hora_pedido                         int32\n",
            "minuto_pedido                       int32\n",
            "dia_semana_pedido                   int32\n",
            "dia_do_ano_pedido                   int32\n",
            "semana_do_ano_pedido                int64\n",
            "dias_desde_cadastro_ate_pedido      int64\n",
            "periodo_dia_pedido                 object\n",
            "dtype: object\n",
            "\n",
            "Colunas restantes:\n",
            "['id_pedido', 'id_cliente', 'idade', 'genero', 'cidade', 'bairro', 'é_estudante', 'frequencia_visita', 'canal_compra', 'forma_pagamento', 'quantidade_itens', 'sabor', 'categoria', 'preco_unitario', 'valor_total_pedido', 'clima', 'ano_cadastro', 'mes_cadastro', 'dia_cadastro', 'dia_semana_cadastro', 'dia_do_ano_cadastro', 'semana_do_ano_cadastro', 'ano_pedido', 'mes_pedido', 'dia_pedido', 'hora_pedido', 'minuto_pedido', 'dia_semana_pedido', 'dia_do_ano_pedido', 'semana_do_ano_pedido', 'dias_desde_cadastro_ate_pedido', 'periodo_dia_pedido']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Separando features (X) e alvo (y)\n",
        "X_geladinhos_df = base_geladinhos.drop('sabor', axis=1) # Ainda como DataFrame\n",
        "y_geladinhos = base_geladinhos['sabor'].values # Seu alvo\n",
        "\n",
        "# Colunas que serão convertidas para array NumPy\n",
        "current_x_columns = X_geladinhos_df.columns.tolist()\n",
        "\n",
        "# Convertendo X para array NumPy AGORA\n",
        "X_geladinhos_np = X_geladinhos_df.values\n",
        "\n",
        "print(\"\\nVerificando os tipos de dados em X_geladinhos_df antes da conversão para NumPy:\")\n",
        "print(X_geladinhos_df.dtypes)\n",
        "# Verifique se não há mais 'datetime64[ns]' ou 'object' que contenha Timestamps"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ifAZ_XJrqQNl",
        "outputId": "440313e3-b975-4504-e1bf-befd978b53c8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Verificando os tipos de dados em X_geladinhos_df antes da conversão para NumPy:\n",
            "id_pedido                           int64\n",
            "id_cliente                          int64\n",
            "idade                               int64\n",
            "genero                             object\n",
            "cidade                             object\n",
            "bairro                             object\n",
            "é_estudante                          bool\n",
            "frequencia_visita                  object\n",
            "canal_compra                       object\n",
            "forma_pagamento                    object\n",
            "quantidade_itens                    int64\n",
            "categoria                          object\n",
            "preco_unitario                    float64\n",
            "valor_total_pedido                float64\n",
            "clima                              object\n",
            "ano_cadastro                        int32\n",
            "mes_cadastro                        int32\n",
            "dia_cadastro                        int32\n",
            "dia_semana_cadastro                 int32\n",
            "dia_do_ano_cadastro                 int32\n",
            "semana_do_ano_cadastro              int64\n",
            "ano_pedido                          int32\n",
            "mes_pedido                          int32\n",
            "dia_pedido                          int32\n",
            "hora_pedido                         int32\n",
            "minuto_pedido                       int32\n",
            "dia_semana_pedido                   int32\n",
            "dia_do_ano_pedido                   int32\n",
            "semana_do_ano_pedido                int64\n",
            "dias_desde_cadastro_ate_pedido      int64\n",
            "periodo_dia_pedido                 object\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Instanciando os LabelEncoders para cada coluna categórica nominal\n",
        "label_enconder_genero = LabelEncoder()\n",
        "label_enconder_cidade = LabelEncoder()\n",
        "label_enconder_bairro = LabelEncoder()\n",
        "label_enconder_frequencia = LabelEncoder()\n",
        "label_enconder_canal_compra = LabelEncoder()\n",
        "label_enconder_forma_pagamento = LabelEncoder()\n",
        "label_enconder_categorias = LabelEncoder()\n",
        "label_encoder_clima = LabelEncoder()\n",
        "label_encoder_periodo_dia = LabelEncoder() # Se 'periodo_dia_pedido' for uma nova coluna categórica\n",
        "\n",
        "# Mapeando nomes das colunas para seus índices numéricos no array NumPy X_geladinhos_np\n",
        "# Use 'current_x_columns' para encontrar os índices corretos\n",
        "idx_genero = current_x_columns.index('genero')\n",
        "idx_cidade = current_x_columns.index('cidade')\n",
        "idx_bairro = current_x_columns.index('bairro')\n",
        "idx_frequencia = current_x_columns.index('frequencia_visita')\n",
        "idx_canal_compra = current_x_columns.index('canal_compra')\n",
        "idx_forma_pagamento = current_x_columns.index('forma_pagamento')\n",
        "idx_categoria = current_x_columns.index('categoria')\n",
        "idx_clima = current_x_columns.index('clima')\n",
        "\n",
        "# Se 'periodo_dia_pedido' foi criado e é categórico\n",
        "if 'periodo_dia_pedido' in current_x_columns:\n",
        "    idx_periodo_dia = current_x_columns.index('periodo_dia_pedido')\n",
        "    X_geladinhos_np[:, idx_periodo_dia] = label_encoder_periodo_dia.fit_transform(X_geladinhos_np[:, idx_periodo_dia])\n",
        "\n",
        "# Aplicando LabelEncoder às colunas do array NumPy X_geladinhos_np\n",
        "X_geladinhos_np[:, idx_genero] = label_enconder_genero.fit_transform(X_geladinhos_np[:, idx_genero])\n",
        "X_geladinhos_np[:, idx_cidade] = label_enconder_cidade.fit_transform(X_geladinhos_np[:, idx_cidade])\n",
        "X_geladinhos_np[:, idx_bairro] = label_enconder_bairro.fit_transform(X_geladinhos_np[:, idx_bairro])\n",
        "X_geladinhos_np[:, idx_frequencia] = label_enconder_frequencia.fit_transform(X_geladinhos_np[:, idx_frequencia])\n",
        "X_geladinhos_np[:, idx_canal_compra] = label_enconder_canal_compra.fit_transform(X_geladinhos_np[:, idx_canal_compra])\n",
        "X_geladinhos_np[:, idx_forma_pagamento] = label_enconder_forma_pagamento.fit_transform(X_geladinhos_np[:, idx_forma_pagamento])\n",
        "X_geladinhos_np[:, idx_categoria] = label_enconder_categorias.fit_transform(X_geladinhos_np[:, idx_categoria])\n",
        "X_geladinhos_np[:, idx_clima] = label_encoder_clima.fit_transform(X_geladinhos_np[:, idx_clima])\n",
        "\n",
        "# Codificando a variável alvo 'sabor' (y_geladinhos)\n",
        "label_encoder_sabor_target = LabelEncoder()\n",
        "y_geladinhos_encoded = label_encoder_sabor_target.fit_transform(y_geladinhos)\n",
        "\n",
        "print(\"\\nTipos de dados das colunas categóricas em X_geladinhos_np (devem ser numéricos agora):\")\n",
        "# Uma forma de verificar é pegar uma amostra e ver os tipos, ou inspecionar o array\n",
        "print(X_geladinhos_np[:5, [idx_genero, idx_cidade, idx_bairro]])"
      ],
      "metadata": {
        "id": "jQuo0RRSv1Ub",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "740f60e6-a654-4b4e-d57a-bd1674c72001"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Tipos de dados das colunas categóricas em X_geladinhos_np (devem ser numéricos agora):\n",
            "[[1 0 327]\n",
            " [0 0 46]\n",
            " [1 0 133]\n",
            " [1 0 442]\n",
            " [0 0 208]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np # Importar numpy caso não tenha sido importado ainda\n",
        "\n",
        "\n",
        "# Identifique os índices das colunas numéricas que devem ser escalonadas.\n",
        "# Use 'current_x_columns' para ter certeza dos índices corretos.\n",
        "numeric_cols_to_scale = [\n",
        "    'idade',\n",
        "    'quantidade_itens',\n",
        "    'preco_unitario',\n",
        "    'valor_total_pedido',\n",
        "    'ano_cadastro',\n",
        "    'mes_cadastro',\n",
        "    'dia_cadastro',\n",
        "    'dia_semana_cadastro',\n",
        "    'dia_do_ano_cadastro',\n",
        "    'semana_do_ano_cadastro',\n",
        "    'ano_pedido',\n",
        "    'mes_pedido',\n",
        "    'dia_pedido',\n",
        "    'hora_pedido',\n",
        "    'minuto_pedido',\n",
        "    'dia_semana_pedido',\n",
        "    'dia_do_ano_pedido',\n",
        "    'semana_do_ano_pedido',\n",
        "    'dias_desde_cadastro_ate_pedido'\n",
        "]\n",
        "\n",
        "indices_to_scale = [current_x_columns.index(col) for col in numeric_cols_to_scale if col in current_x_columns]\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Aplica o scaler SOMENTE às colunas selecionadas\n",
        "# Garanta que os dados nessas colunas são do tipo numérico (int, float) antes de escalonar\n",
        "X_geladinhos_np[:, indices_to_scale] = X_geladinhos_np[:, indices_to_scale].astype(float) # Garante que são float\n",
        "\n",
        "X_geladinhos_np[:, indices_to_scale] = scaler.fit_transform(X_geladinhos_np[:, indices_to_scale])\n",
        "\n",
        "print(\"Média das colunas escalonadas (deve ser próximo de 0):\")\n",
        "print(np.mean(X_geladinhos_np[:, indices_to_scale], axis=0))\n",
        "print(\"\\nDesvio padrão das colunas escalonadas (deve ser próximo de 1):\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jx8pLTFG7p0K",
        "outputId": "60315516-15d0-4bf2-fa2a-9993ad3d7b08"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Média das colunas escalonadas (deve ser próximo de 0):\n",
            "[1.4919177004912855e-16 -6.323309931222099e-17 0.0 -2.7308320535435194e-16\n",
            " 5.130460500879508e-14 5.684341886080802e-18 -6.159517340620368e-17\n",
            " 8.635314685534468e-17 -1.857403120197887e-17 -1.36590738719633e-16\n",
            " -6.871909707939494e-14 2.0194956817931597e-16 7.209233210403454e-17\n",
            " 2.6756374893466272e-17 5.540012892879531e-17 7.660094780703731e-16\n",
            " -9.039435866498025e-17 -2.2093438190040616e-17 8.919531779838508e-17]\n",
            "\n",
            "Desvio padrão das colunas escalonadas (deve ser próximo de 1):\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Dividindo os dados: 80% para treino, 20% para teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_geladinhos_np, y_geladinhos_encoded, test_size=0.2, random_state=42, stratify=y_geladinhos_encoded\n",
        ")\n",
        "\n",
        "print(f\"Formato de X_train: {X_train.shape}\")\n",
        "print(f\"Formato de X_test: {X_test.shape}\")\n",
        "print(f\"Formato de y_train: {y_train.shape}\")\n",
        "print(f\"Formato de y_test: {y_test.shape}\")\n",
        "\n",
        "# Instanciando e treinando o modelo Random Forest Classifier\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "print(\"\\nTreinando o modelo...\")\n",
        "model.fit(X_train, y_train)\n",
        "print(\"Modelo treinado com sucesso!\")\n",
        "\n",
        "# Fazendo previsões no conjunto de teste\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# --- Avaliação do Modelo ---\n",
        "print(\"\\n--- Avaliação do Modelo ---\")\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Acurácia do Modelo: {accuracy:.4f}\")\n",
        "\n",
        "print(\"\\nRelatório de Classificação:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"\\nMatriz de Confusão:\")\n",
        "print(confusion_matrix(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "id": "E01Mn0GZ79v-",
        "outputId": "57a9fee9-a12e-46a1-d77c-32102077b0bb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_test_split' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-1412610474>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Dividindo os dados: 80% para treino, 20% para teste\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m X_train, X_test, y_train, y_test = train_test_split(\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mX_geladinhos_np\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_geladinhos_encoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstratify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_geladinhos_encoded\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m )\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_test_split' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "\n",
        "# --- ATENÇÃO: É CRUCIAL QUE OS OBJETOS ABAIXO TENHAM SIDO CRIADOS E 'FIT'ADOS NO SEU PIPELINE DE PRÉ-PROCESSAMENTO ANTERIOR ---\n",
        "# Se você está rodando as células em sequência em um ambiente de notebook, eles já estarão disponíveis.\n",
        "# Caso contrário, você precisaria carregar/re-fitá-los.\n",
        "\n",
        "# Exemplo de como você teria esses objetos (apenas para ilustrar, eles já devem existir no seu ambiente)\n",
        "# label_encoder_genero = LabelEncoder().fit(base_geladinhos['genero']) # Exemplo\n",
        "# ... e assim por diante para todos os LabelEncoders, o scaler e o encoder do alvo.\n",
        "\n",
        "# A maneira mais segura de garantir que você tem todos os objetos 'fit'ados é:\n",
        "# 1. Rodar todo o seu pipeline de pré-processamento (desde o carregamento dos dados até o escalonamento)\n",
        "#    em uma única sessão de kernel ou script.\n",
        "# 2. Salvar/carregar esses objetos (encoders, scaler) usando `joblib` ou `pickle` se você precisar\n",
        "#    usá-los em sessões diferentes. Por enquanto, vamos assumir que eles estão na memória.\n",
        "\n",
        "# Relembrar os nomes das colunas de X_df na ordem correta\n",
        "# Isso é essencial para saber onde cada dado de entrada deve ir.\n",
        "# A variável `current_x_columns_after_processing` deve vir do seu código anterior.\n",
        "# Se não estiver disponível, você pode recriá-la após o Label Encoding, mas antes do .values\n",
        "# Exemplo:\n",
        "# X_df = base_geladinhos.drop('sabor', axis=1) # Após todas as manipulações de data\n",
        "# # Aplique Label Encoders aqui em X_df\n",
        "# current_x_columns_after_processing = X_df.columns.tolist()\n",
        "\n",
        "\n",
        "def sugerir_sabor_geladinho(dados_entrada_usuario: dict):\n",
        "    \"\"\"\n",
        "    Sugere o sabor do geladinho com base nos dados fornecidos pelo usuário.\n",
        "\n",
        "    Args:\n",
        "        dados_entrada_usuario (dict): Um dicionário contendo os dados do usuário.\n",
        "                                      As chaves do dicionário devem corresponder aos nomes\n",
        "                                      das colunas do seu DataFrame original (antes de processar datas e LabelEncode).\n",
        "                                      Exemplo:\n",
        "                                      {\n",
        "                                          'id_pedido': 99999,\n",
        "                                          'id_cliente': 99999,\n",
        "                                          'data_cadastro': '2023-01-15',\n",
        "                                          'idade': 30,\n",
        "                                          'genero': 'Feminino',\n",
        "                                          'cidade': 'Santos',\n",
        "                                          'bairro': 'Boqueirão',\n",
        "                                          'é_estudante': True,\n",
        "                                          'frequencia_visita': 'Semanal',\n",
        "                                          'data_hora_pedido': '2024-06-15 10:30:00',\n",
        "                                          'canal_compra': 'Online',\n",
        "                                          'forma_pagamento': 'Cartão de Crédito',\n",
        "                                          'quantidade_itens': 1,\n",
        "                                          'preco_unitario': 7.0,\n",
        "                                          'valor_total_pedido': 7.0,\n",
        "                                          'clima': 'Quente'\n",
        "                                      }\n",
        "\n",
        "    Returns:\n",
        "        str: O sabor de geladinho sugerido pelo modelo.\n",
        "             Retorna \"Erro no processamento dos dados.\" se houver um problema.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # 1. Criar um DataFrame a partir dos dados do usuário\n",
        "        # Colunas devem ser as mesmas do seu base_geladinhos original, excluindo 'sabor'.\n",
        "        # Isso é fundamental para manter a ordem e o nome das colunas durante o pré-processamento.\n",
        "        input_df = pd.DataFrame([dados_entrada_usuario])\n",
        "\n",
        "        # Garantir que a coluna 'é_estudante' é booleana\n",
        "        input_df['é_estudante'] = input_df['é_estudante'].astype(bool)\n",
        "\n",
        "        # 2. TRATAMENTO DAS COLUNAS DE DATA E HORA (EXATAMENTE COMO NO TREINO)\n",
        "        input_df['data_cadastro'] = pd.to_datetime(input_df['data_cadastro'])\n",
        "        input_df['data_hora_pedido'] = pd.to_datetime(input_df['data_hora_pedido'])\n",
        "\n",
        "        input_df['ano_cadastro'] = input_df['data_cadastro'].dt.year\n",
        "        input_df['mes_cadastro'] = input_df['data_cadastro'].dt.month\n",
        "        input_df['dia_cadastro'] = input_df['data_cadastro'].dt.day\n",
        "        input_df['dia_semana_cadastro'] = input_df['data_cadastro'].dt.dayofweek\n",
        "        input_df['dia_do_ano_cadastro'] = input_df['data_cadastro'].dt.dayofyear\n",
        "        input_df['semana_do_ano_cadastro'] = input_df['data_cadastro'].dt.isocalendar().week.astype(int)\n",
        "\n",
        "        input_df['ano_pedido'] = input_df['data_hora_pedido'].dt.year\n",
        "        input_df['mes_pedido'] = input_df['data_hora_pedido'].dt.month\n",
        "        input_df['dia_pedido'] = input_df['data_hora_pedido'].dt.day\n",
        "        input_df['hora_pedido'] = input_df['data_hora_pedido'].dt.hour\n",
        "        input_df['minuto_pedido'] = input_df['data_hora_pedido'].dt.minute\n",
        "        input_df['dia_semana_pedido'] = input_df['data_hora_pedido'].dt.dayofweek\n",
        "        input_df['dia_do_ano_pedido'] = input_df['data_hora_pedido'].dt.dayofyear\n",
        "        input_df['semana_do_ano_pedido'] = input_df['data_hora_pedido'].dt.isocalendar().week.astype(int)\n",
        "\n",
        "        input_df['dias_desde_cadastro_ate_pedido'] = (input_df['data_hora_pedido'] - input_df['data_cadastro']).dt.days\n",
        "\n",
        "        # Função período_do_dia deve ser a mesma\n",
        "        def periodo_do_dia(hora):\n",
        "            if 5 <= hora < 12:\n",
        "                return 'manha'\n",
        "            elif 12 <= hora < 18:\n",
        "                return 'tarde'\n",
        "            else:\n",
        "                return 'noite'\n",
        "\n",
        "        input_df['periodo_dia_pedido'] = input_df['hora_pedido'].apply(periodo_do_dia)\n",
        "\n",
        "        # Remover as colunas originais de data/hora\n",
        "        input_df = input_df.drop(columns=['data_cadastro', 'data_hora_pedido'])\n",
        "\n",
        "        # Remover colunas que são IDs e que não foram usadas no treino do X\n",
        "        # As colunas 'id_pedido', 'id_cliente' não devem ser passadas para o modelo\n",
        "        # Remova-as se ainda estiverem no input_df\n",
        "        input_df = input_df.drop(columns=['id_pedido', 'id_cliente'])\n",
        "\n",
        "        # 3. APLICAR LABEL ENCODER NAS COLUNAS CATEGÓRICAS (EXATAMENTE COMO NO TREINO)\n",
        "        # É CRUCIAL USAR OS MESMOS ENCODERS QUE FORAM FITADOS NO TREINO!\n",
        "        # Use .transform() aqui, nunca .fit_transform() em novos dados.\n",
        "        input_df['genero'] = label_encoder_genero.transform(input_df['genero'])\n",
        "        input_df['cidade'] = label_encoder_cidade.transform(input_df['cidade'])\n",
        "        input_df['bairro'] = label_encoder_bairro.transform(input_df['bairro'])\n",
        "        input_df['frequencia_visita'] = label_encoder_frequencia.transform(input_df['frequencia_visita'])\n",
        "        input_df['canal_compra'] = label_encoder_canal_compra.transform(input_df['canal_compra'])\n",
        "        input_df['forma_pagamento'] = label_encoder_forma_pagamento.transform(input_df['forma_pagamento'])\n",
        "        input_df['categoria'] = label_encoder_categorias.transform(input_df['categoria'])\n",
        "        input_df['clima'] = label_encoder_clima.transform(input_df['clima'])\n",
        "        input_df['periodo_dia_pedido'] = label_encoder_periodo_dia.transform(input_df['periodo_dia_pedido'])\n",
        "\n",
        "\n",
        "        # Garantir que a coluna 'é_estudante' é int (se já não for do LabelEncoder)\n",
        "        input_df['é_estudante'] = input_df['é_estudante'].astype(int)\n",
        "\n",
        "        # 4. CONVERTER PARA ARRAY NUMPY E ESCALAR AS COLUNAS NUMÉRICAS\n",
        "        # A ordem das colunas no input_np deve ser a MESMA ordem que X_train\n",
        "        # Para isso, usaremos `current_x_columns_after_processing` para reordenar.\n",
        "\n",
        "        # Garanta que todas as colunas de input_df são numéricas (int/float) ou já foram codificadas\n",
        "        for col in input_df.columns:\n",
        "            if input_df[col].dtype == 'object':\n",
        "                # Isso deve pegar qualquer string que ainda não foi transformada\n",
        "                # Exemplo: se uma nova categoria apareceu que o encoder não conhece, isso pode falhar.\n",
        "                # Para LabelEncoder, a melhor prática é que as categorias de teste estejam nas categorias de treino.\n",
        "                # Se houver uma categoria desconhecida, .transform() levantará um ValueError.\n",
        "                # Você pode adicionar um bloco try-except aqui ou garantir que seus dados de teste\n",
        "                # estejam dentro do vocabulário do encoder.\n",
        "                pass # Se chegou até aqui, espera-se que não haja mais 'object' não numérico\n",
        "\n",
        "\n",
        "        # Reordenar as colunas de input_df para corresponderem à ordem de X_train\n",
        "        # `current_x_columns_after_processing` é a lista de colunas de X_df antes do .values no treino\n",
        "        input_np = input_df[current_x_columns_after_processing].values\n",
        "\n",
        "        # Escalar as colunas numéricas (EXATAMENTE COMO NO TREINO, USANDO O MESMO SCALER)\n",
        "        # Lembre-se dos `indices_to_scale` que você calculou antes\n",
        "        input_np[:, indices_to_scale] = scaler.transform(input_np[:, indices_to_scale])\n",
        "\n",
        "        # 5. Fazer a previsão\n",
        "        previsao_codificada = model.predict(input_np)\n",
        "\n",
        "        # 6. Decodificar a previsão de volta para o nome do sabor\n",
        "        sabor_sugerido = label_encoder_sabor_target.inverse_transform(previsao_codificada)\n",
        "\n",
        "        return sabor_sugerido[0] # Retorna o primeiro (e único) elemento do array\n",
        "\n",
        "    except ValueError as ve:\n",
        "        # Isso pode acontecer se uma categoria de entrada não foi vista durante o treinamento (em .transform())\n",
        "        return f\"Erro: Uma categoria de entrada não foi reconhecida. Detalhes: {ve}\"\n",
        "    except Exception as e:\n",
        "        return f\"Ocorreu um erro no processamento dos dados ou na previsão: {e}\""
      ],
      "metadata": {
        "id": "bYA-2cB8-z-x"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exemplo de dados de entrada de um novo cliente\n",
        "novos_dados_cliente = {\n",
        "    'id_pedido': 10001,\n",
        "    'id_cliente': 10001,\n",
        "    'data_cadastro': '2023-05-10', # Formato 'YYYY-MM-DD'\n",
        "    'idade': 28,\n",
        "    'genero': 'Feminino',\n",
        "    'cidade': 'Santos',\n",
        "    'bairro': 'Ponta da Praia', # Assegure-se que este bairro foi visto no treino ou que o encoder lida com novos\n",
        "    'é_estudante': False,\n",
        "    'frequencia_visita': 'Mensal',\n",
        "    'data_hora_pedido': '2024-06-15 15:45:00', # Formato 'YYYY-MM-DD HH:MM:SS'\n",
        "    'canal_compra': 'Aplicativo',\n",
        "    'forma_pagamento': 'PIX',\n",
        "    'quantidade_itens': 3,\n",
        "    'preco_unitario': 6.5,\n",
        "    'valor_total_pedido': 19.5,\n",
        "    'clima': 'Frio'\n",
        "}\n",
        "\n",
        "sabor_sugerido = sugerir_sabor_geladinho(novos_dados_cliente)\n",
        "print(f\"\\nPara os dados fornecidos, o sabor de geladinho sugerido é: {sabor_sugerido}\")\n",
        "\n",
        "# Outro exemplo\n",
        "novos_dados_cliente_2 = {\n",
        "    'id_pedido': 10002,\n",
        "    'id_cliente': 10002,\n",
        "    'data_cadastro': '2024-01-01',\n",
        "    'idade': 45,\n",
        "    'genero': 'Masculino',\n",
        "    'cidade': 'São Vicente',\n",
        "    'bairro': 'Centro',\n",
        "    'é_estudante': True,\n",
        "    'frequencia_visita': 'Semanal',\n",
        "    'data_hora_pedido': '2024-06-15 20:00:00',\n",
        "    'canal_compra': 'Unidade Física Boqueirão',\n",
        "    'forma_pagamento': 'Dinheiro',\n",
        "    'quantidade_itens': 2,\n",
        "    'preco_unitario': 7.0,\n",
        "    'valor_total_pedido': 14.0,\n",
        "    'clima': 'Quente'\n",
        "}\n",
        "\n",
        "sabor_sugerido_2 = sugerir_sabor_geladinho(novos_dados_cliente_2)\n",
        "print(f\"\\nPara os dados do cliente 2, o sabor de geladinho sugerido é: {sabor_sugerido_2}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38bWUZ9J-4Ro",
        "outputId": "2085573c-f05b-42e2-d462-dc5a6af46789"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Para os dados fornecidos, o sabor de geladinho sugerido é: Ocorreu um erro no processamento dos dados ou na previsão: name 'label_encoder_genero' is not defined\n",
            "\n",
            "Para os dados do cliente 2, o sabor de geladinho sugerido é: Ocorreu um erro no processamento dos dados ou na previsão: name 'label_encoder_genero' is not defined\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# --- PARTE 1: PRÉ-PROCESSAMENTO DOS DADOS (Rodar tudo isso primeiro!) ---\n",
        "base_geladinhos = pd.read_csv('geladinhos.csv')\n",
        "\n",
        "print(\"Iniciando o pré-processamento dos dados...\")\n",
        "\n",
        "# 1. Tratamento das colunas de data e hora\n",
        "base_geladinhos['data_cadastro'] = pd.to_datetime(base_geladinhos['data_cadastro'])\n",
        "base_geladinhos['data_hora_pedido'] = pd.to_datetime(base_geladinhos['data_hora_pedido'])\n",
        "\n",
        "base_geladinhos['ano_cadastro'] = base_geladinhos['data_cadastro'].dt.year\n",
        "base_geladinhos['mes_cadastro'] = base_geladinhos['data_cadastro'].dt.month\n",
        "base_geladinhos['dia_cadastro'] = base_geladinhos['data_cadastro'].dt.day\n",
        "base_geladinhos['dia_semana_cadastro'] = base_geladinhos['data_cadastro'].dt.dayofweek\n",
        "base_geladinhos['dia_do_ano_cadastro'] = base_geladinhos['data_cadastro'].dt.dayofyear\n",
        "base_geladinhos['semana_do_ano_cadastro'] = base_geladinhos['data_cadastro'].dt.isocalendar().week.astype(int)\n",
        "\n",
        "base_geladinhos['ano_pedido'] = base_geladinhos['data_hora_pedido'].dt.year\n",
        "base_geladinhos['mes_pedido'] = base_geladinhos['data_hora_pedido'].dt.month\n",
        "base_geladinhos['dia_pedido'] = base_geladinhos['data_hora_pedido'].dt.day\n",
        "base_geladinhos['hora_pedido'] = base_geladinhos['data_hora_pedido'].dt.hour\n",
        "base_geladinhos['minuto_pedido'] = base_geladinhos['data_hora_pedido'].dt.minute\n",
        "base_geladinhos['dia_semana_pedido'] = base_geladinhos['data_hora_pedido'].dt.dayofweek\n",
        "base_geladinhos['dia_do_ano_pedido'] = base_geladinhos['data_hora_pedido'].dt.dayofyear\n",
        "base_geladinhos['semana_do_ano_pedido'] = base_geladinhos['data_hora_pedido'].dt.isocalendar().week.astype(int)\n",
        "\n",
        "base_geladinhos['dias_desde_cadastro_ate_pedido'] = (base_geladinhos['data_hora_pedido'] - base_geladinhos['data_cadastro']).dt.days\n",
        "\n",
        "def periodo_do_dia(hora):\n",
        "    if 5 <= hora < 12:\n",
        "        return 'manha'\n",
        "    elif 12 <= hora < 18:\n",
        "        return 'tarde'\n",
        "    else:\n",
        "        return 'noite'\n",
        "\n",
        "base_geladinhos['periodo_dia_pedido'] = base_geladinhos['hora_pedido'].apply(periodo_do_dia)\n",
        "\n",
        "# REMOVER as colunas originais de data/hora AGORA\n",
        "base_geladinhos = base_geladinhos.drop(columns=['data_cadastro', 'data_hora_pedido'])\n",
        "print(\"  - Colunas de data/hora processadas e removidas.\")\n",
        "\n",
        "# 2. Dividir em Features (X_df) e Alvo (y_geladinhos)\n",
        "# Remova também 'id_pedido' e 'id_cliente' de X_df aqui, pois não serão features para o modelo\n",
        "X_df = base_geladinhos.drop(columns=['sabor', 'id_pedido', 'id_cliente'], axis=1) # CORREÇÃO AQUI\n",
        "y_geladinhos = base_geladinhos['sabor'].values\n",
        "print(\"  - Dados divididos em X (DataFrame) e y (NumPy array), com IDs removidos de X.\")\n",
        "\n",
        "# 3. Aplicar LabelEncoder nas colunas categóricas do X_df\n",
        "label_encoder_genero = LabelEncoder()\n",
        "label_encoder_cidade = LabelEncoder()\n",
        "label_encoder_bairro = LabelEncoder()\n",
        "label_encoder_frequencia = LabelEncoder()\n",
        "label_encoder_canal_compra = LabelEncoder()\n",
        "label_encoder_forma_pagamento = LabelEncoder()\n",
        "label_encoder_categorias = LabelEncoder()\n",
        "label_encoder_clima = LabelEncoder()\n",
        "label_encoder_periodo_dia = LabelEncoder()\n",
        "\n",
        "most_frequent_categories = {}\n",
        "\n",
        "def fit_and_store_most_frequent(encoder, column_name, df_column):\n",
        "    encoder.fit(df_column)\n",
        "    most_frequent = df_column.mode()[0]\n",
        "    most_frequent_categories[column_name] = most_frequent\n",
        "    return encoder.transform(df_column)\n",
        "\n",
        "X_df['genero'] = fit_and_store_most_frequent(label_encoder_genero, 'genero', X_df['genero'])\n",
        "X_df['cidade'] = fit_and_store_most_frequent(label_encoder_cidade, 'cidade', X_df['cidade'])\n",
        "X_df['bairro'] = fit_and_store_most_frequent(label_encoder_bairro, 'bairro', X_df['bairro'])\n",
        "X_df['frequencia_visita'] = fit_and_store_most_frequent(label_encoder_frequencia, 'frequencia_visita', X_df['frequencia_visita'])\n",
        "X_df['canal_compra'] = fit_and_store_most_frequent(label_encoder_canal_compra, 'canal_compra', X_df['canal_compra'])\n",
        "X_df['forma_pagamento'] = fit_and_store_most_frequent(label_encoder_forma_pagamento, 'forma_pagamento', X_df['forma_pagamento'])\n",
        "X_df['categoria'] = fit_and_store_most_frequent(label_encoder_categorias, 'categoria', X_df['categoria'])\n",
        "X_df['clima'] = fit_and_store_most_frequent(label_encoder_clima, 'clima', X_df['clima'])\n",
        "X_df['periodo_dia_pedido'] = fit_and_store_most_frequent(label_encoder_periodo_dia, 'periodo_dia_pedido', X_df['periodo_dia_pedido'])\n",
        "\n",
        "X_df['é_estudante'] = X_df['é_estudante'].astype(int)\n",
        "print(\"  - Colunas categóricas em X_df codificadas com LabelEncoder.\")\n",
        "\n",
        "label_encoder_sabor_target = LabelEncoder()\n",
        "y_geladinhos_encoded = label_encoder_sabor_target.fit_transform(y_geladinhos)\n",
        "print(\"  - Variável alvo (sabor) codificada.\")\n",
        "\n",
        "# 4. Obter a lista de colunas APÓS TODAS AS REMOÇÕES E TRANSFORMAÇÕES NO DATAFRAME X_df\n",
        "# ESTA É A LISTA QUE DEVE SER USADA PARA MANTER A ORDEM!\n",
        "current_x_columns_after_processing = X_df.columns.tolist() # CORREÇÃO AQUI\n",
        "print(f\"  - Ordem final das colunas em X: {current_x_columns_after_processing}\")\n",
        "\n",
        "\n",
        "numeric_cols_to_scale = [\n",
        "    'idade', 'quantidade_itens', 'preco_unitario', 'valor_total_pedido',\n",
        "    'ano_cadastro', 'mes_cadastro', 'dia_cadastro', 'dia_semana_cadastro', 'dia_do_ano_cadastro', 'semana_do_ano_cadastro',\n",
        "    'ano_pedido', 'mes_pedido', 'dia_pedido', 'hora_pedido', 'minuto_pedido', 'dia_semana_pedido', 'dia_do_ano_pedido', 'semana_do_ano_pedido',\n",
        "    'dias_desde_cadastro_ate_pedido'\n",
        "]\n",
        "\n",
        "indices_to_scale = [current_x_columns_after_processing.index(col) for col in numeric_cols_to_scale if col in current_x_columns_after_processing]\n",
        "\n",
        "X_geladinhos_np = X_df.values\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_geladinhos_np[:, indices_to_scale] = scaler.fit_transform(X_geladinhos_np[:, indices_to_scale])\n",
        "print(\"  - Colunas numéricas escalonadas.\")\n",
        "print(f\"  - Tipo de dados final de X_geladinhos_np: {X_geladinhos_np.dtype}\")\n",
        "\n",
        "# 5. Divisão em Treino e Teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_geladinhos_np, y_geladinhos_encoded, test_size=0.2, random_state=42, stratify=y_geladinhos_encoded\n",
        ")\n",
        "print(\"  - Dados divididos em conjuntos de treino e teste.\")\n",
        "\n",
        "# 6. Treinamento do Modelo\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "print(\"  - Treinando o modelo...\")\n",
        "model.fit(X_train, y_train)\n",
        "print(\"  - Modelo treinado com sucesso!\")\n",
        "print(\"\\nPré-processamento e treinamento concluídos com sucesso!\")\n",
        "\n",
        "# --- PARTE 2: FUNÇÃO DE SUGESTÃO E TESTE (Rodar esta parte DEPOIS da Parte 1) ---\n",
        "\n",
        "def sugerir_sabor_geladinho(dados_entrada_usuario: dict):\n",
        "    try:\n",
        "        input_df = pd.DataFrame([dados_entrada_usuario])\n",
        "\n",
        "        input_df['é_estudante'] = input_df['é_estudante'].astype(bool)\n",
        "\n",
        "        # Tratamento de datas\n",
        "        input_df['data_cadastro'] = pd.to_datetime(input_df['data_cadastro'])\n",
        "        input_df['data_hora_pedido'] = pd.to_datetime(input_df['data_hora_pedido'])\n",
        "\n",
        "        input_df['ano_cadastro'] = input_df['data_cadastro'].dt.year\n",
        "        input_df['mes_cadastro'] = input_df['data_cadastro'].dt.month\n",
        "        input_df['dia_cadastro'] = input_df['data_cadastro'].dt.day\n",
        "        input_df['dia_semana_cadastro'] = input_df['data_cadastro'].dt.dayofweek\n",
        "        input_df['dia_do_ano_cadastro'] = input_df['data_cadastro'].dt.dayofyear\n",
        "        input_df['semana_do_ano_cadastro'] = input_df['data_cadastro'].dt.isocalendar().week.astype(int)\n",
        "\n",
        "        input_df['ano_pedido'] = input_df['data_hora_pedido'].dt.year\n",
        "        input_df['mes_pedido'] = input_df['data_hora_pedido'].dt.month\n",
        "        input_df['dia_pedido'] = input_df['data_hora_pedido'].dt.day\n",
        "        input_df['hora_pedido'] = input_df['data_hora_pedido'].dt.hour\n",
        "        input_df['minuto_pedido'] = input_df['data_hora_pedido'].dt.minute\n",
        "        input_df['dia_semana_pedido'] = input_df['data_hora_pedido'].dt.dayofweek\n",
        "        input_df['dia_do_ano_pedido'] = input_df['data_hora_pedido'].dt.dayofyear\n",
        "        input_df['semana_do_ano_pedido'] = input_df['data_hora_pedido'].dt.isocalendar().week.astype(int)\n",
        "\n",
        "        input_df['dias_desde_cadastro_ate_pedido'] = (input_df['data_hora_pedido'] - input_df['data_cadastro']).dt.days\n",
        "\n",
        "        input_df['periodo_dia_pedido'] = input_df['hora_pedido'].apply(periodo_do_dia)\n",
        "\n",
        "        # Remover as colunas originais de data/hora e IDs de input_df\n",
        "        input_df = input_df.drop(columns=['data_cadastro', 'data_hora_pedido', 'id_pedido', 'id_cliente']) # JÁ REMOVE AQUI\n",
        "\n",
        "        # Aplicar LabelEncoder (usando os encoders GLOBALMENTE DISPONÍVEIS)\n",
        "        encoders_map = {\n",
        "            'genero': label_encoder_genero,\n",
        "            'cidade': label_encoder_cidade,\n",
        "            'bairro': label_encoder_bairro,\n",
        "            'frequencia_visita': label_encoder_frequencia,\n",
        "            'canal_compra': label_encoder_canal_compra,\n",
        "            'forma_pagamento': label_encoder_forma_pagamento,\n",
        "            'categoria': label_encoder_categorias,\n",
        "            'clima': label_encoder_clima,\n",
        "            'periodo_dia_pedido': label_encoder_periodo_dia\n",
        "        }\n",
        "\n",
        "        for col_name, encoder in encoders_map.items():\n",
        "            if col_name in input_df.columns: # Verifica se a coluna existe no input_df atual\n",
        "                freq_cat = most_frequent_categories.get(col_name)\n",
        "                unknown_mask = ~input_df[col_name].isin(encoder.classes_)\n",
        "                if unknown_mask.any():\n",
        "                    print(f\"  Aviso: Categoria(s) desconhecida(s) em '{col_name}' no input. Substituindo por '{freq_cat}'.\")\n",
        "                    input_df.loc[unknown_mask, col_name] = freq_cat\n",
        "                input_df[col_name] = encoder.transform(input_df[col_name])\n",
        "\n",
        "        input_df['é_estudante'] = input_df['é_estudante'].astype(int)\n",
        "\n",
        "        # Converter para NumPy array e garantir a ordem das colunas\n",
        "        # 'current_x_columns_after_processing' agora já NÃO CONTÉM 'id_pedido', 'id_cliente', 'sabor'\n",
        "        input_np = input_df[current_x_columns_after_processing].values # AGORA ISSO DEVE FUNCIONAR\n",
        "\n",
        "        # Escalar as colunas numéricas\n",
        "        input_np[:, indices_to_scale] = scaler.transform(input_np[:, indices_to_scale])\n",
        "\n",
        "        # Fazer a previsão\n",
        "        previsao_codificada = model.predict(input_np)\n",
        "\n",
        "        # Decodificar a previsão\n",
        "        sabor_sugerido = label_encoder_sabor_target.inverse_transform(previsao_codificada)\n",
        "\n",
        "        return sabor_sugerido[0]\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"Ocorreu um erro no processamento dos dados ou na previsão: {e}\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03OKh9U4_L2o",
        "outputId": "e7b0deaa-4a1b-4d5f-f571-8871a2fa1df8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iniciando o pré-processamento dos dados...\n",
            "  - Colunas de data/hora processadas e removidas.\n",
            "  - Dados divididos em X (DataFrame) e y (NumPy array), com IDs removidos de X.\n",
            "  - Colunas categóricas em X_df codificadas com LabelEncoder.\n",
            "  - Variável alvo (sabor) codificada.\n",
            "  - Ordem final das colunas em X: ['idade', 'genero', 'cidade', 'bairro', 'é_estudante', 'frequencia_visita', 'canal_compra', 'forma_pagamento', 'quantidade_itens', 'categoria', 'preco_unitario', 'valor_total_pedido', 'clima', 'ano_cadastro', 'mes_cadastro', 'dia_cadastro', 'dia_semana_cadastro', 'dia_do_ano_cadastro', 'semana_do_ano_cadastro', 'ano_pedido', 'mes_pedido', 'dia_pedido', 'hora_pedido', 'minuto_pedido', 'dia_semana_pedido', 'dia_do_ano_pedido', 'semana_do_ano_pedido', 'dias_desde_cadastro_ate_pedido', 'periodo_dia_pedido']\n",
            "  - Colunas numéricas escalonadas.\n",
            "  - Tipo de dados final de X_geladinhos_np: float64\n",
            "  - Dados divididos em conjuntos de treino e teste.\n",
            "  - Treinando o modelo...\n",
            "  - Modelo treinado com sucesso!\n",
            "\n",
            "Pré-processamento e treinamento concluídos com sucesso!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- TESTANDO A FUNÇÃO ---\n",
        "\n",
        "# Exemplo de dados de entrada de um novo cliente\n",
        "novos_dados_cliente = {\n",
        "    'id_pedido': 10001,\n",
        "    'id_cliente': 10001,\n",
        "    'data_cadastro': '2023-05-10',\n",
        "    'idade': 28,\n",
        "    'genero': 'Feminino',\n",
        "    'cidade': 'Santos',\n",
        "    'bairro': 'Ponta da Praia',\n",
        "    'é_estudante': False,\n",
        "    'frequencia_visita': 'Mensal',\n",
        "    'data_hora_pedido': '2024-06-15 15:45:00',\n",
        "    'canal_compra': 'Aplicativo',\n",
        "    'forma_pagamento': 'PIX',\n",
        "    'quantidade_itens': 3,\n",
        "    'preco_unitario': 6.5,\n",
        "    'valor_total_pedido': 19.5,\n",
        "    'clima': 'Frio'\n",
        "}\n",
        "\n",
        "sabor_sugerido = sugerir_sabor_geladinho(novos_dados_cliente)\n",
        "print(f\"\\nPara os dados fornecidos, o sabor de geladinho sugerido é: {sabor_sugerido}\")\n",
        "\n",
        "# Outro exemplo\n",
        "novos_dados_cliente_2 = {\n",
        "    'id_pedido': 10002,\n",
        "    'id_cliente': 10002,\n",
        "    'data_cadastro': '2024-01-01',\n",
        "    'idade': 45,\n",
        "    'genero': 'Masculino',\n",
        "    'cidade': 'São Vicente',\n",
        "    'bairro': 'Centro',\n",
        "    'é_estudante': True,\n",
        "    'frequencia_visita': 'Semanal',\n",
        "    'data_hora_pedido': '2024-06-15 20:00:00',\n",
        "    'canal_compra': 'Unidade Física Boqueirão',\n",
        "    'forma_pagamento': 'Dinheiro',\n",
        "    'quantidade_itens': 2,\n",
        "    'preco_unitario': 7.0,\n",
        "    'valor_total_pedido': 14.0,\n",
        "    'clima': 'Quente'\n",
        "}\n",
        "\n",
        "sabor_sugerido_2 = sugerir_sabor_geladinho(novos_dados_cliente_2)\n",
        "print(f\"\\nPara os dados do cliente 2, o sabor de geladinho sugerido é: {sabor_sugerido_2}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rux09Sok_kNe",
        "outputId": "05c6c123-96f4-4280-d0fb-e52eb9c5418c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Aviso: Categoria(s) desconhecida(s) em 'bairro' no input. Substituindo por 'Cardoso'.\n",
            "  Aviso: Categoria(s) desconhecida(s) em 'canal_compra' no input. Substituindo por 'Unidade Física Pompéia'.\n",
            "\n",
            "Para os dados fornecidos, o sabor de geladinho sugerido é: Ocorreu um erro no processamento dos dados ou na previsão: \"['categoria'] not in index\"\n",
            "  Aviso: Categoria(s) desconhecida(s) em 'cidade' no input. Substituindo por 'Santos'.\n",
            "\n",
            "Para os dados do cliente 2, o sabor de geladinho sugerido é: Ocorreu um erro no processamento dos dados ou na previsão: \"['categoria'] not in index\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# --- PART 1: DATA PREPROCESSING (Run all this first!) ---\n",
        "base_geladinhos = pd.read_csv('geladinhos.csv')\n",
        "\n",
        "\n",
        "print(\"Starting data preprocessing...\")\n",
        "\n",
        "# Assuming 'base_geladinhos' is already loaded.\n",
        "# If not, uncomment and load your data:\n",
        "# base_geladinhos = pd.read_csv('your_data_file.csv') # Replace with your file path\n",
        "\n",
        "# 1. Date and Time Column Handling\n",
        "base_geladinhos['data_cadastro'] = pd.to_datetime(base_geladinhos['data_cadastro'])\n",
        "base_geladinhos['data_hora_pedido'] = pd.to_datetime(base_geladinhos['data_hora_pedido'])\n",
        "\n",
        "base_geladinhos['ano_cadastro'] = base_geladinhos['data_cadastro'].dt.year\n",
        "base_geladinhos['mes_cadastro'] = base_geladinhos['data_cadastro'].dt.month\n",
        "base_geladinhos['dia_cadastro'] = base_geladinhos['data_cadastro'].dt.day\n",
        "base_geladinhos['dia_semana_cadastro'] = base_geladinhos['data_cadastro'].dt.dayofweek\n",
        "base_geladinhos['dia_do_ano_cadastro'] = base_geladinhos['data_cadastro'].dt.dayofyear\n",
        "base_geladinhos['semana_do_ano_cadastro'] = base_geladinhos['data_cadastro'].dt.isocalendar().week.astype(int)\n",
        "\n",
        "base_geladinhos['ano_pedido'] = base_geladinhos['data_hora_pedido'].dt.year\n",
        "base_geladinhos['mes_pedido'] = base_geladinhos['data_hora_pedido'].dt.month\n",
        "base_geladinhos['dia_pedido'] = base_geladinhos['data_hora_pedido'].dt.day\n",
        "base_geladinhos['hora_pedido'] = base_geladinhos['data_hora_pedido'].dt.hour\n",
        "base_geladinhos['minuto_pedido'] = base_geladinhos['data_hora_pedido'].dt.minute\n",
        "base_geladinhos['dia_semana_pedido'] = base_geladinhos['data_hora_pedido'].dt.dayofweek\n",
        "base_geladinhos['dia_do_ano_pedido'] = base_geladinhos['data_hora_pedido'].dt.dayofyear\n",
        "base_geladinhos['semana_do_ano_pedido'] = base_geladinhos['data_hora_pedido'].dt.isocalendar().week.astype(int)\n",
        "\n",
        "base_geladinhos['dias_desde_cadastro_ate_pedido'] = (base_geladinhos['data_hora_pedido'] - base_geladinhos['data_cadastro']).dt.days\n",
        "\n",
        "def periodo_do_dia(hora):\n",
        "    if 5 <= hora < 12:\n",
        "        return 'manha'\n",
        "    elif 12 <= hora < 18:\n",
        "        return 'tarde'\n",
        "    else:\n",
        "        return 'noite'\n",
        "\n",
        "base_geladinhos['periodo_dia_pedido'] = base_geladinhos['hora_pedido'].apply(periodo_do_dia)\n",
        "\n",
        "# Remove original date/time columns NOW\n",
        "base_geladinhos = base_geladinhos.drop(columns=['data_cadastro', 'data_hora_pedido'])\n",
        "print(\"  - Date/time columns processed and removed.\")\n",
        "\n",
        "# 2. Split into Features (X_df) and Target (y_geladinhos)\n",
        "# Ensure 'id_pedido' and 'id_cliente' are dropped from X_df, but NOT 'categoria'\n",
        "X_df = base_geladinhos.drop(columns=['sabor', 'id_pedido', 'id_cliente'], axis=1) # Corrected here\n",
        "y_geladinhos = base_geladinhos['sabor'].values\n",
        "print(\"  - Data split into X (DataFrame) and y (NumPy array), with IDs removed from X.\")\n",
        "\n",
        "# 3. Apply LabelEncoder to categorical columns in X_df\n",
        "label_encoder_genero = LabelEncoder()\n",
        "label_encoder_cidade = LabelEncoder()\n",
        "label_encoder_bairro = LabelEncoder()\n",
        "label_encoder_frequencia = LabelEncoder()\n",
        "label_encoder_canal_compra = LabelEncoder()\n",
        "label_encoder_forma_pagamento = LabelEncoder()\n",
        "label_encoder_categorias = LabelEncoder() # This encoder is for 'categoria'\n",
        "label_encoder_clima = LabelEncoder()\n",
        "label_encoder_periodo_dia = LabelEncoder()\n",
        "\n",
        "most_frequent_categories = {}\n",
        "\n",
        "def fit_and_store_most_frequent(encoder, column_name, df_column):\n",
        "    encoder.fit(df_column)\n",
        "    most_frequent = df_column.mode()[0]\n",
        "    most_frequent_categories[column_name] = most_frequent\n",
        "    return encoder.transform(df_column)\n",
        "\n",
        "X_df['genero'] = fit_and_store_most_frequent(label_encoder_genero, 'genero', X_df['genero'])\n",
        "X_df['cidade'] = fit_and_store_most_frequent(label_encoder_cidade, 'cidade', X_df['cidade'])\n",
        "X_df['bairro'] = fit_and_store_most_frequent(label_encoder_bairro, 'bairro', X_df['bairro'])\n",
        "X_df['frequencia_visita'] = fit_and_store_most_frequent(label_encoder_frequencia, 'frequencia_visita', X_df['frequencia_visita'])\n",
        "X_df['canal_compra'] = fit_and_store_most_frequent(label_encoder_canal_compra, 'canal_compra', X_df['canal_compra'])\n",
        "X_df['forma_pagamento'] = fit_and_store_most_frequent(label_encoder_forma_pagamento, 'forma_pagamento', X_df['forma_pagamento'])\n",
        "X_df['categoria'] = fit_and_store_most_frequent(label_encoder_categorias, 'categoria', X_df['categoria']) # Ensure 'categoria' is processed\n",
        "X_df['clima'] = fit_and_store_most_frequent(label_encoder_clima, 'clima', X_df['clima'])\n",
        "X_df['periodo_dia_pedido'] = fit_and_store_most_frequent(label_encoder_periodo_dia, 'periodo_dia_pedido', X_df['periodo_dia_pedido'])\n",
        "\n",
        "X_df['é_estudante'] = X_df['é_estudante'].astype(int)\n",
        "print(\"  - Categorical columns in X_df encoded with LabelEncoder.\")\n",
        "\n",
        "label_encoder_sabor_target = LabelEncoder()\n",
        "y_geladinhos_encoded = label_encoder_sabor_target.fit_transform(y_geladinhos)\n",
        "print(\"  - Target variable (sabor) encoded.\")\n",
        "\n",
        "# 4. Get the final list of columns AFTER ALL REMOVALS AND TRANSFORMATIONS IN X_df\n",
        "# This list will be used to maintain order in the prediction function\n",
        "current_x_columns_after_processing = X_df.columns.tolist()\n",
        "print(f\"  - Final order of columns in X: {current_x_columns_after_processing}\")\n",
        "\n",
        "\n",
        "numeric_cols_to_scale = [\n",
        "    'idade', 'quantidade_itens', 'preco_unitario', 'valor_total_pedido',\n",
        "    'ano_cadastro', 'mes_cadastro', 'dia_cadastro', 'dia_semana_cadastro', 'dia_do_ano_cadastro', 'semana_do_ano_cadastro',\n",
        "    'ano_pedido', 'mes_pedido', 'dia_pedido', 'hora_pedido', 'minuto_pedido', 'dia_semana_pedido', 'dia_do_ano_pedido', 'semana_do_ano_pedido',\n",
        "    'dias_desde_cadastro_ate_pedido'\n",
        "]\n",
        "\n",
        "indices_to_scale = [current_x_columns_after_processing.index(col) for col in numeric_cols_to_scale if col in current_x_columns_after_processing]\n",
        "\n",
        "X_geladinhos_np = X_df.values\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_geladinhos_np[:, indices_to_scale] = scaler.fit_transform(X_geladinhos_np[:, indices_to_scale])\n",
        "print(\"  - Numerical columns scaled.\")\n",
        "print(f\"  - Final data type of X_geladinhos_np: {X_geladinhos_np.dtype}\")\n",
        "\n",
        "# 5. Split into Training and Test Sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_geladinhos_np, y_geladinhos_encoded, test_size=0.2, random_state=42, stratify=y_geladinhos_encoded\n",
        ")\n",
        "print(\"  - Data split into training and test sets.\")\n",
        "\n",
        "# 6. Model Training\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "print(\"  - Training the model...\")\n",
        "model.fit(X_train, y_train)\n",
        "print(\"  - Model trained successfully!\")\n",
        "print(\"\\nPreprocessing and training completed successfully!\")\n",
        "\n",
        "\n",
        "def sugerir_sabor_geladinho(dados_entrada_usuario: dict):\n",
        "    try:\n",
        "        input_df = pd.DataFrame([dados_entrada_usuario])\n",
        "\n",
        "        input_df['é_estudante'] = input_df['é_estudante'].astype(bool)\n",
        "\n",
        "        # Date handling\n",
        "        input_df['data_cadastro'] = pd.to_datetime(input_df['data_cadastro'])\n",
        "        input_df['data_hora_pedido'] = pd.to_datetime(input_df['data_hora_pedido'])\n",
        "\n",
        "        input_df['ano_cadastro'] = input_df['data_cadastro'].dt.year\n",
        "        input_df['mes_cadastro'] = input_df['data_cadastro'].dt.month\n",
        "        input_df['dia_cadastro'] = input_df['data_cadastro'].dt.day\n",
        "        input_df['dia_semana_cadastro'] = input_df['data_cadastro'].dt.dayofweek\n",
        "        input_df['dia_do_ano_cadastro'] = input_df['data_cadastro'].dt.dayofyear\n",
        "        input_df['semana_do_ano_cadastro'] = input_df['data_cadastro'].dt.isocalendar().week.astype(int)\n",
        "\n",
        "        input_df['ano_pedido'] = input_df['data_hora_pedido'].dt.year\n",
        "        input_df['mes_pedido'] = input_df['data_hora_pedido'].dt.month\n",
        "        input_df['dia_pedido'] = input_df['data_hora_pedido'].dt.day\n",
        "        input_df['hora_pedido'] = input_df['data_hora_pedido'].dt.hour\n",
        "        input_df['minuto_pedido'] = input_df['data_hora_pedido'].dt.minute\n",
        "        input_df['dia_semana_pedido'] = input_df['data_hora_pedido'].dt.dayofweek\n",
        "        input_df['dia_do_ano_pedido'] = input_df['data_hora_pedido'].dt.dayofyear\n",
        "        input_df['semana_do_ano_pedido'] = input_df['data_hora_pedido'].dt.isocalendar().week.astype(int)\n",
        "\n",
        "        input_df['dias_desde_cadastro_ate_pedido'] = (input_df['data_hora_pedido'] - input_df['data_cadastro']).dt.days\n",
        "\n",
        "        input_df['periodo_dia_pedido'] = input_df['hora_pedido'].apply(periodo_do_dia)\n",
        "\n",
        "        # Remove original date/time columns and IDs from input_df\n",
        "        # ENSURE 'categoria' IS NOT IN THIS DROP LIST\n",
        "        input_df = input_df.drop(columns=['data_cadastro', 'data_hora_pedido', 'id_pedido', 'id_cliente']) # 'categoria' is not here\n",
        "\n",
        "        # Apply LabelEncoder (using globally available encoders)\n",
        "        encoders_map = {\n",
        "            'genero': label_encoder_genero,\n",
        "            'cidade': label_encoder_cidade,\n",
        "            'bairro': label_encoder_bairro,\n",
        "            'frequencia_visita': label_encoder_frequencia,\n",
        "            'canal_compra': label_encoder_canal_compra,\n",
        "            'forma_pagamento': label_encoder_forma_pagamento,\n",
        "            'categoria': label_encoder_categorias, # 'categoria' is here for encoding\n",
        "            'clima': label_encoder_clima,\n",
        "            'periodo_dia_pedido': label_encoder_periodo_dia\n",
        "        }\n",
        "\n",
        "        for col_name, encoder in encoders_map.items():\n",
        "            if col_name in input_df.columns: # Check if the column exists in the current input_df\n",
        "                freq_cat = most_frequent_categories.get(col_name)\n",
        "                unknown_mask = ~input_df[col_name].isin(encoder.classes_)\n",
        "                if unknown_mask.any():\n",
        "                    print(f\"  Warning: Unknown category(ies) in '{col_name}' in input. Replacing with '{freq_cat}'.\")\n",
        "                    input_df.loc[unknown_mask, col_name] = freq_cat\n",
        "                input_df[col_name] = encoder.transform(input_df[col_name])\n",
        "\n",
        "        input_df['é_estudante'] = input_df['é_estudante'].astype(int)\n",
        "\n",
        "        # Convert to NumPy array and ensure column order\n",
        "        # 'current_x_columns_after_processing' now correctly excludes 'id_pedido', 'id_cliente', 'sabor'\n",
        "        # And importantly, 'categoria' *is* expected to be in both input_df and current_x_columns_after_processing\n",
        "        input_np = input_df[current_x_columns_after_processing].values # This line should now work\n",
        "\n",
        "        # Scale numerical columns\n",
        "        input_np[:, indices_to_scale] = scaler.transform(input_np[:, indices_to_scale])\n",
        "\n",
        "        # Make prediction\n",
        "        previsao_codificada = model.predict(input_np)\n",
        "\n",
        "        # Decode prediction\n",
        "        sabor_sugerido = label_encoder_sabor_target.inverse_transform(previsao_codificada)\n",
        "\n",
        "        return sabor_sugerido[0]\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"An error occurred during data processing or prediction: {e}\"\n",
        "\n",
        "# --- TESTING THE FUNCTION ---\n",
        "\n",
        "# Example user input data\n",
        "new_client_data = {\n",
        "    'id_pedido': 10001,\n",
        "    'id_cliente': 10001,\n",
        "    'data_cadastro': '2023-05-10',\n",
        "    'idade': 28,\n",
        "    'genero': 'Feminino',\n",
        "    'cidade': 'Santos',\n",
        "    'bairro': 'Ponta da Praia', # This category will be replaced if unseen\n",
        "    'é_estudante': False,\n",
        "    'frequencia_visita': 'Mensal',\n",
        "    'data_hora_pedido': '2024-06-15 15:45:00',\n",
        "    'canal_compra': 'Aplicativo',\n",
        "    'forma_pagamento': 'PIX',\n",
        "    'quantidade_itens': 3,\n",
        "    'preco_unitario': 6.5,\n",
        "    'valor_total_pedido': 19.5,\n",
        "    'clima': 'Frio',\n",
        "    'categoria': 'Geladinhos Premium' # Ensure 'categoria' is always provided in user input\n",
        "}\n",
        "\n",
        "suggested_flavor = sugerir_sabor_geladinho(new_client_data)\n",
        "print(f\"\\nFor the provided data, the suggested geladinho flavor is: {suggested_flavor}\")\n",
        "\n",
        "# Another example\n",
        "new_client_data_2 = {\n",
        "    'id_pedido': 10002,\n",
        "    'id_cliente': 10002,\n",
        "    'data_cadastro': '2024-01-01',\n",
        "    'idade': 45,\n",
        "    'genero': 'Masculino',\n",
        "    'cidade': 'São Vicente', # This category will be replaced if unseen\n",
        "    'bairro': 'Centro',\n",
        "    'é_estudante': True,\n",
        "    'frequencia_visita': 'Semanal',\n",
        "    'data_hora_pedido': '2024-06-15 20:00:00',\n",
        "    'canal_compra': 'Unidade Física Boqueirão',\n",
        "    'forma_pagamento': 'Dinheiro',\n",
        "    'quantidade_itens': 2,\n",
        "    'preco_unitario': 7.0,\n",
        "    'valor_total_pedido': 14.0,\n",
        "    'clima': 'Quente',\n",
        "    'categoria': 'Geladinhos Tradicionais' # Ensure 'categoria' is always provided\n",
        "}\n",
        "\n",
        "suggested_flavor_2 = sugerir_sabor_geladinho(new_client_data_2)\n",
        "print(f\"\\nFor client 2's data, the suggested geladinho flavor is: {suggested_flavor_2}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0uzTuPFqBdPf",
        "outputId": "c697a128-0d9a-49e0-8637-76b89bd314c9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting data preprocessing...\n",
            "  - Date/time columns processed and removed.\n",
            "  - Data split into X (DataFrame) and y (NumPy array), with IDs removed from X.\n",
            "  - Categorical columns in X_df encoded with LabelEncoder.\n",
            "  - Target variable (sabor) encoded.\n",
            "  - Final order of columns in X: ['idade', 'genero', 'cidade', 'bairro', 'é_estudante', 'frequencia_visita', 'canal_compra', 'forma_pagamento', 'quantidade_itens', 'categoria', 'preco_unitario', 'valor_total_pedido', 'clima', 'ano_cadastro', 'mes_cadastro', 'dia_cadastro', 'dia_semana_cadastro', 'dia_do_ano_cadastro', 'semana_do_ano_cadastro', 'ano_pedido', 'mes_pedido', 'dia_pedido', 'hora_pedido', 'minuto_pedido', 'dia_semana_pedido', 'dia_do_ano_pedido', 'semana_do_ano_pedido', 'dias_desde_cadastro_ate_pedido', 'periodo_dia_pedido']\n",
            "  - Numerical columns scaled.\n",
            "  - Final data type of X_geladinhos_np: float64\n",
            "  - Data split into training and test sets.\n",
            "  - Training the model...\n",
            "  - Model trained successfully!\n",
            "\n",
            "Preprocessing and training completed successfully!\n",
            "  Warning: Unknown category(ies) in 'bairro' in input. Replacing with 'Cardoso'.\n",
            "  Warning: Unknown category(ies) in 'canal_compra' in input. Replacing with 'Unidade Física Pompéia'.\n",
            "  Warning: Unknown category(ies) in 'categoria' in input. Replacing with 'Frutinhas'.\n",
            "\n",
            "For the provided data, the suggested geladinho flavor is: Coco Queimado\n",
            "  Warning: Unknown category(ies) in 'cidade' in input. Replacing with 'Santos'.\n",
            "  Warning: Unknown category(ies) in 'categoria' in input. Replacing with 'Frutinhas'.\n",
            "\n",
            "For client 2's data, the suggested geladinho flavor is: Coco\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "VKd40GDd5R0d"
      }
    }
  ]
}